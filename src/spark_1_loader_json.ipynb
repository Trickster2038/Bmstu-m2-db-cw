{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1c96b38-20f3-4050-bfbe-007a8c4767e8",
   "metadata": {},
   "source": [
    "UI example: https://dev.to/mvillarrealb/creating-a-spark-standalone-cluster-with-docker-and-docker-compose-2021-update-6l4\n",
    "\n",
    "APP UI: https://stackoverflow.com/questions/56397738/sparkui-not-showing-tab-jobs-stages-storage-environment-when-run-in-sta\n",
    "\n",
    "My job UI: http://localhost:4050/jobs/ (порты задач 404Х на хосте будут 405Х)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5acbfd6-e671-46ab-ae75-6391f1c47fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "import json\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "06264946-bda3-413a-a9a3-5bfb897c36b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = Elasticsearch(\"http://localhost:9200\")\n",
    "client.ping()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6fb0812-d079-45b4-9c1f-82afec2ed1f1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ConnectionError",
     "evalue": "Connection error caused by: ConnectionError(Connection error caused by: ProtocolError(('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 9\u001b[0m\n\u001b[0;32m      1\u001b[0m searchBody \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      2\u001b[0m   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msize\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m9999\u001b[39m,\n\u001b[0;32m      3\u001b[0m   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_source\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      6\u001b[0m   }\n\u001b[0;32m      7\u001b[0m }\n\u001b[1;32m----> 9\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaster\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msearchBody\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m masters \u001b[38;5;241m=\u001b[39m result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhits\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhits\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     11\u001b[0m result \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39msearch(index\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124morder\u001b[39m\u001b[38;5;124m\"\u001b[39m, body\u001b[38;5;241m=\u001b[39msearchBody)\n",
      "File \u001b[1;32mc:\\users\\sergey.astakhov\\desktop\\bmstu-m2-db-cw\\venv\\lib\\site-packages\\elasticsearch\\_sync\\client\\utils.py:426\u001b[0m, in \u001b[0;36m_rewrite_parameters.<locals>.wrapper.<locals>.wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    423\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m    424\u001b[0m             \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m--> 426\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m api(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\users\\sergey.astakhov\\desktop\\bmstu-m2-db-cw\\venv\\lib\\site-packages\\elasticsearch\\_sync\\client\\__init__.py:3836\u001b[0m, in \u001b[0;36mElasticsearch.search\u001b[1;34m(self, index, aggregations, aggs, allow_no_indices, allow_partial_search_results, analyze_wildcard, analyzer, batched_reduce_size, ccs_minimize_roundtrips, collapse, default_operator, df, docvalue_fields, error_trace, expand_wildcards, explain, ext, fields, filter_path, from_, highlight, human, ignore_throttled, ignore_unavailable, indices_boost, knn, lenient, max_concurrent_shard_requests, min_compatible_shard_node, min_score, pit, post_filter, pre_filter_shard_size, preference, pretty, profile, q, query, rank, request_cache, rescore, rest_total_hits_as_int, routing, runtime_mappings, script_fields, scroll, search_after, search_type, seq_no_primary_term, size, slice, sort, source, source_excludes, source_includes, stats, stored_fields, suggest, suggest_field, suggest_mode, suggest_size, suggest_text, terminate_after, timeout, track_scores, track_total_hits, typed_keys, version, body)\u001b[0m\n\u001b[0;32m   3834\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m __body \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3835\u001b[0m     __headers[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent-type\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapplication/json\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 3836\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mperform_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[return-value]\u001b[39;49;00m\n\u001b[0;32m   3837\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPOST\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m__path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m__query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m__headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m__body\u001b[49m\n\u001b[0;32m   3838\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\users\\sergey.astakhov\\desktop\\bmstu-m2-db-cw\\venv\\lib\\site-packages\\elasticsearch\\_sync\\client\\_base.py:285\u001b[0m, in \u001b[0;36mBaseClient.perform_request\u001b[1;34m(self, method, path, params, headers, body)\u001b[0m\n\u001b[0;32m    282\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    283\u001b[0m     target \u001b[38;5;241m=\u001b[39m path\n\u001b[1;32m--> 285\u001b[0m meta, resp_body \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mperform_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    286\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    287\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    288\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    289\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_max_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry_on_status\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_on_status\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry_on_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_on_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient_meta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client_meta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    295\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    297\u001b[0m \u001b[38;5;66;03m# HEAD with a 404 is returned as a normal response\u001b[39;00m\n\u001b[0;32m    298\u001b[0m \u001b[38;5;66;03m# since this is used as an 'exists' functionality.\u001b[39;00m\n\u001b[0;32m    299\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHEAD\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m meta\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m404\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[0;32m    300\u001b[0m     \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m meta\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m299\u001b[39m\n\u001b[0;32m    301\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    305\u001b[0m     )\n\u001b[0;32m    306\u001b[0m ):\n",
      "File \u001b[1;32mc:\\users\\sergey.astakhov\\desktop\\bmstu-m2-db-cw\\venv\\lib\\site-packages\\elastic_transport\\_transport.py:328\u001b[0m, in \u001b[0;36mTransport.perform_request\u001b[1;34m(self, method, target, body, headers, max_retries, retry_on_status, retry_on_timeout, request_timeout, client_meta)\u001b[0m\n\u001b[0;32m    326\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 328\u001b[0m     meta, raw_data \u001b[38;5;241m=\u001b[39m \u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mperform_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    329\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    330\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    331\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    332\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    333\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    334\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    335\u001b[0m     _logger\u001b[38;5;241m.\u001b[39minfo(\n\u001b[0;32m    336\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m [status:\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m duration:\u001b[39m\u001b[38;5;132;01m%.3f\u001b[39;00m\u001b[38;5;124ms]\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    337\u001b[0m         \u001b[38;5;241m%\u001b[39m (\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    343\u001b[0m         )\n\u001b[0;32m    344\u001b[0m     )\n\u001b[0;32m    346\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHEAD\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\users\\sergey.astakhov\\desktop\\bmstu-m2-db-cw\\venv\\lib\\site-packages\\elastic_transport\\_node\\_http_urllib3.py:202\u001b[0m, in \u001b[0;36mUrllib3HttpNode.perform_request\u001b[1;34m(self, method, target, body, headers, request_timeout)\u001b[0m\n\u001b[0;32m    194\u001b[0m         err \u001b[38;5;241m=\u001b[39m \u001b[38;5;167;01mConnectionError\u001b[39;00m(\u001b[38;5;28mstr\u001b[39m(e), errors\u001b[38;5;241m=\u001b[39m(e,))\n\u001b[0;32m    195\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_request(\n\u001b[0;32m    196\u001b[0m         method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[0;32m    197\u001b[0m         target\u001b[38;5;241m=\u001b[39mtarget,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    200\u001b[0m         exception\u001b[38;5;241m=\u001b[39merr,\n\u001b[0;32m    201\u001b[0m     )\n\u001b[1;32m--> 202\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m err \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    204\u001b[0m meta \u001b[38;5;241m=\u001b[39m ApiResponseMeta(\n\u001b[0;32m    205\u001b[0m     node\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig,\n\u001b[0;32m    206\u001b[0m     duration\u001b[38;5;241m=\u001b[39mduration,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    209\u001b[0m     headers\u001b[38;5;241m=\u001b[39mresponse_headers,\n\u001b[0;32m    210\u001b[0m )\n\u001b[0;32m    211\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_request(\n\u001b[0;32m    212\u001b[0m     method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[0;32m    213\u001b[0m     target\u001b[38;5;241m=\u001b[39mtarget,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    217\u001b[0m     response\u001b[38;5;241m=\u001b[39mdata,\n\u001b[0;32m    218\u001b[0m )\n",
      "\u001b[1;31mConnectionError\u001b[0m: Connection error caused by: ConnectionError(Connection error caused by: ProtocolError(('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))))"
     ]
    }
   ],
   "source": [
    "searchBody = {\n",
    "  \"size\": 9999,\n",
    "  \"_source\": True,\n",
    "  \"query\": {\n",
    "    \"match_all\": {}\n",
    "  }\n",
    "}\n",
    "\n",
    "result = client.search(index=\"master\", body=searchBody)\n",
    "masters = result['hits']['hits']\n",
    "result = client.search(index=\"order\", body=searchBody)\n",
    "orders = result['hits']['hits']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ef52ce-6e87-4f37-bf9b-8cdf5d47e9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "masters[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410d7c31-b073-40d4-bac1-ea38cd37d698",
   "metadata": {},
   "outputs": [],
   "source": [
    "orders[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0537e3c7-891e-4b63-b3fe-c1cb22805d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "masters = {}\n",
    "orders = {}\n",
    "\n",
    "with open('../spark_masters.json', 'w') as f:\n",
    "    json.dump(masters, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "65a91c78-cdd6-44c8-919e-adf9a1790819",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../spark_orders.json', 'w') as f:\n",
    "    json.dump(orders, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee48669-98a4-4c35-9fa4-69bdd5dcdc64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "167a119b-2493-442c-b20d-7e8f40f78504",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.getoutput('docker cp ../spark_masters.json spark-master:/spark_masters.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "88fce8fd-e868-4db5-9d58-aff60849101d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.getoutput('docker cp ../spark_orders.json spark-master:/spark_orders.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8db79e14-4885-433f-b55a-1e99b794858b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.getoutput('docker cp ../spark_2_csv.py spark-master:/spark_2_csv.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "045a2c51-ce19-4ae9-92f4-821e9e8261ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bin\\ndev\\netc\\nexecute-step.sh\\nfinish-step.sh\\nhome\\nlib\\nlib64\\nmaster.sh\\nmedia\\nmnt\\nopt\\nproc\\nroot\\nrun\\nsbin\\nspark\\nspark_2_csv.py\\nspark_3_process.py\\nspark_masters.json\\nspark_orders.json\\nsrv\\nsys\\ntmp\\nusr\\nvar\\nwait-for-step.sh'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.getoutput('docker exec spark-master ls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b6ee2e-6862-43c2-9a68-012c53a7923c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(subprocess.getoutput('docker exec spark-master /spark/bin/spark-submit --master spark://spark-master:7077 spark_2_csv.py'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b39c5bd4-bca6-4dfc-9517-a9a229aa3965",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.getoutput('docker cp ../spark_3_process.py spark-master:/spark_3_process.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "12c65faa-56a4-4192-b16c-ab375959eaee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --deploy-mode cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b534c873-1765-4d9b-9082-99f6d83cb129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: can't create directory '/tmp/spark-events': File exists\n"
     ]
    }
   ],
   "source": [
    "print(subprocess.getoutput('docker exec spark-master mkdir /tmp/spark-events'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "42eb0217-1b15-441d-a714-ce4f82fc876b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/02/24 19:14:55 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "24/02/24 19:14:56 INFO SparkContext: Running Spark version 3.0.0\n",
      "24/02/24 19:14:56 INFO ResourceUtils: ==============================================================\n",
      "24/02/24 19:14:56 INFO ResourceUtils: Resources for spark.driver:\n",
      "\n",
      "24/02/24 19:14:56 INFO ResourceUtils: ==============================================================\n",
      "24/02/24 19:14:56 INFO SparkContext: Submitted application: cw_process_3\n",
      "24/02/24 19:14:56 INFO SecurityManager: Changing view acls to: root\n",
      "24/02/24 19:14:56 INFO SecurityManager: Changing modify acls to: root\n",
      "24/02/24 19:14:56 INFO SecurityManager: Changing view acls groups to: \n",
      "24/02/24 19:14:56 INFO SecurityManager: Changing modify acls groups to: \n",
      "24/02/24 19:14:56 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()\n",
      "24/02/24 19:14:56 INFO Utils: Successfully started service 'sparkDriver' on port 36327.\n",
      "24/02/24 19:14:56 INFO SparkEnv: Registering MapOutputTracker\n",
      "24/02/24 19:14:56 INFO SparkEnv: Registering BlockManagerMaster\n",
      "24/02/24 19:14:56 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information\n",
      "24/02/24 19:14:56 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up\n",
      "24/02/24 19:14:56 INFO SparkEnv: Registering BlockManagerMasterHeartbeat\n",
      "24/02/24 19:14:56 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-441effed-78e9-443e-a228-eb6fc2b47538\n",
      "24/02/24 19:14:56 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB\n",
      "24/02/24 19:14:56 INFO SparkEnv: Registering OutputCommitCoordinator\n",
      "24/02/24 19:14:57 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "24/02/24 19:14:57 INFO Utils: Successfully started service 'SparkUI' on port 4041.\n",
      "24/02/24 19:14:57 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://87da9a22fd0b:4041\n",
      "24/02/24 19:14:57 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...\n",
      "24/02/24 19:14:57 INFO TransportClientFactory: Successfully created connection to spark-master/172.20.0.11:7077 after 44 ms (0 ms spent in bootstraps)\n",
      "24/02/24 19:14:57 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20240224191457-0003\n",
      "24/02/24 19:14:57 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 43875.\n",
      "24/02/24 19:14:57 INFO NettyBlockTransferService: Server created on 87da9a22fd0b:43875\n",
      "24/02/24 19:14:57 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy\n",
      "24/02/24 19:14:57 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 87da9a22fd0b, 43875, None)\n",
      "24/02/24 19:14:57 INFO BlockManagerMasterEndpoint: Registering block manager 87da9a22fd0b:43875 with 366.3 MiB RAM, BlockManagerId(driver, 87da9a22fd0b, 43875, None)\n",
      "24/02/24 19:14:57 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 87da9a22fd0b, 43875, None)\n",
      "24/02/24 19:14:57 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 87da9a22fd0b, 43875, None)\n",
      "24/02/24 19:14:58 INFO SingleEventLogFileWriter: Logging events to file:/tmp/spark-events/app-20240224191457-0003.inprogress\n",
      "24/02/24 19:14:58 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0\n",
      "/spark/python/lib/pyspark.zip/pyspark/context.py:220: DeprecationWarning: Support for Python 2 and Python 3 prior to version 3.6 is deprecated as of Spark 3.0. See also the plan for dropping Python 2 support at https://spark.apache.org/news/plan-for-dropping-python-2-support.html.\n",
      "  DeprecationWarning)\n",
      "24/02/24 19:14:59 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/spark-warehouse').\n",
      "24/02/24 19:14:59 INFO SharedState: Warehouse path is 'file:/spark-warehouse'.\n",
      "24/02/24 19:17:05 INFO StandaloneAppClient$ClientEndpoint: Master removed worker worker-20240224184157-172.20.0.12-37601: Not receiving heartbeat for 60 seconds\n",
      "24/02/24 19:17:05 INFO StandaloneSchedulerBackend: Worker worker-20240224184157-172.20.0.12-37601 removed: Not receiving heartbeat for 60 seconds\n",
      "24/02/24 19:17:06 INFO TaskSchedulerImpl: Handle removed worker worker-20240224184157-172.20.0.12-37601: Not receiving heartbeat for 60 seconds\n",
      "24/02/24 19:17:06 INFO DAGScheduler: Shuffle files lost for worker worker-20240224184157-172.20.0.12-37601 on host 172.20.0.12\n",
      "24/02/24 19:17:09 INFO InMemoryFileIndex: It took 306 ms to list leaf files for 1 paths.\n",
      "24/02/24 19:17:09 INFO InMemoryFileIndex: It took 20 ms to list leaf files for 2 paths.\n",
      "24/02/24 19:17:13 INFO FileSourceStrategy: Pruning directories with: \n",
      "24/02/24 19:17:13 INFO FileSourceStrategy: Pushed Filters: \n",
      "24/02/24 19:17:13 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)\n",
      "24/02/24 19:17:13 INFO FileSourceStrategy: Output Data Schema: struct<value: string>\n",
      "24/02/24 19:17:14 INFO CodeGenerator: Code generated in 255.220876 ms\n",
      "24/02/24 19:17:14 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 303.0 KiB, free 366.0 MiB)\n",
      "24/02/24 19:17:14 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 27.4 KiB, free 366.0 MiB)\n",
      "24/02/24 19:17:14 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 87da9a22fd0b:43875 (size: 27.4 KiB, free: 366.3 MiB)\n",
      "24/02/24 19:17:14 INFO SparkContext: Created broadcast 0 from load at NativeMethodAccessorImpl.java:0\n",
      "24/02/24 19:17:14 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194343 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "24/02/24 19:17:14 INFO SparkContext: Starting job: load at NativeMethodAccessorImpl.java:0\n",
      "24/02/24 19:17:14 INFO DAGScheduler: Got job 0 (load at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "24/02/24 19:17:14 INFO DAGScheduler: Final stage: ResultStage 0 (load at NativeMethodAccessorImpl.java:0)\n",
      "24/02/24 19:17:14 INFO DAGScheduler: Parents of final stage: List()\n",
      "24/02/24 19:17:14 INFO DAGScheduler: Missing parents: List()\n",
      "24/02/24 19:17:14 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at load at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "24/02/24 19:17:14 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 10.7 KiB, free 366.0 MiB)\n",
      "24/02/24 19:17:14 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.3 KiB, free 366.0 MiB)\n",
      "24/02/24 19:17:14 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 87da9a22fd0b:43875 (size: 5.3 KiB, free: 366.3 MiB)\n",
      "24/02/24 19:17:14 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1200\n",
      "24/02/24 19:17:14 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at load at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "24/02/24 19:17:14 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks\n",
      "24/02/24 19:17:29 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "24/02/24 19:17:44 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "24/02/24 19:17:59 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "24/02/24 19:19:02 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "24/02/24 19:19:02 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "24/02/24 19:19:02 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "24/02/24 19:19:02 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "24/02/24 19:19:03 INFO StandaloneAppClient$ClientEndpoint: Master removed worker worker-20240224184157-172.20.0.12-37601: Not receiving heartbeat for 60 seconds\n",
      "24/02/24 19:19:03 INFO StandaloneSchedulerBackend: Worker worker-20240224184157-172.20.0.12-37601 removed: Not receiving heartbeat for 60 seconds\n",
      "24/02/24 19:19:03 INFO TaskSchedulerImpl: Handle removed worker worker-20240224184157-172.20.0.12-37601: Not receiving heartbeat for 60 seconds\n",
      "24/02/24 19:19:03 INFO DAGScheduler: Shuffle files lost for worker worker-20240224184157-172.20.0.12-37601 on host 172.20.0.12\n",
      "24/02/24 19:19:15 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "24/02/24 19:19:29 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "24/02/24 19:19:44 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "24/02/24 19:19:59 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "24/02/24 19:20:14 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "24/02/24 19:20:29 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "24/02/24 19:20:31 INFO StandaloneAppClient$ClientEndpoint: Master removed worker worker-20240224184157-172.20.0.12-37601: 172.20.0.12:37601 got disassociated\n",
      "24/02/24 19:20:31 INFO StandaloneSchedulerBackend: Worker worker-20240224184157-172.20.0.12-37601 removed: 172.20.0.12:37601 got disassociated\n",
      "24/02/24 19:20:31 INFO TaskSchedulerImpl: Handle removed worker worker-20240224184157-172.20.0.12-37601: 172.20.0.12:37601 got disassociated\n",
      "24/02/24 19:20:31 INFO DAGScheduler: Shuffle files lost for worker worker-20240224184157-172.20.0.12-37601 on host 172.20.0.12\n"
     ]
    }
   ],
   "source": [
    "print(subprocess.getoutput('docker exec spark-master /spark/bin/spark-submit --master spark://spark-master:7077 spark_3_process.py'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088ed473-ba39-46f5-ae7d-92798f198eb9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
